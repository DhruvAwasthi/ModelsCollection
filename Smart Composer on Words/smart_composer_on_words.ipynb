{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "smart_composer_on_words.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6B1IwYUSs_U",
        "colab_type": "text"
      },
      "source": [
        "# Create the corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWRLsbCdFvI8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "7a370a2a-5a27-4303-a6e2-9bb7191d7cf0"
      },
      "source": [
        "!pip install pymupdf\n",
        "import fitz\n",
        "import nltk.data\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('words')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymupdf\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/a1/11e63fd3746e0e6e07e71226cb51ef8a3cc2a2ad5577be04e8470035ce4a/PyMuPDF-1.17.5-cp36-cp36m-manylinux2010_x86_64.whl (6.0MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0MB 4.2MB/s \n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.17.5\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgAAmY09WIM0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07a6892e-0f18-4465-fa6f-7cc835a4710c"
      },
      "source": [
        "corpus = ['set', 'value', 'description', 'time', 'flow', 'process', 'screen', 'check', 'gas', 'wafer', 'line', 'module', 'operation', 'equipment', 'pressure', 'parameter', 'command', 'rate', 'display', 'setting', 'manual', 'set value', 'description set', 'value description', 'flow rate', 'set whether', 'gas line', 'process module', 'accept command', 'auto check', 'value sec', 'sec description', 'see page', 'pm parameter', 'limit level', 'gas flow', 'time set', 'logging data', 'value disable', 'enable disable', 'set value description', 'value description set', 'description set whether', 'set value sec', 'value sec description', 'sec description set', 'set value disable', 'time set value', 'set whether accept', 'whether accept command']\n",
        "len(corpus)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4FkUrwES84w",
        "colab_type": "text"
      },
      "source": [
        "# Start building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqd4V4RHJQpE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "412fa9f6-f898-43da-d856-3ce76ff2e668"
      },
      "source": [
        "# Let's start building the model\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Flatten, TimeDistributed, Dropout, LSTMCell, RNN, Bidirectional, Concatenate, Layer\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.python.keras.utils import tf_utils\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, os \n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tSB6_dKLpQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_dataset(corpus):  \n",
        "    output = []\n",
        "    for line in corpus:\n",
        "        token_list = line\n",
        "        for i in range(1, len(token_list)):\n",
        "            data = []\n",
        "            x_ngram = '<start> '+ token_list[:i+1] + ' <end>'\n",
        "            y_ngram = '<start> '+ token_list[i+1:] + ' <end>'\n",
        "            data.append(x_ngram)\n",
        "            data.append(y_ngram)\n",
        "            output.append(data)\n",
        "    print(\"Dataset prepared with prefix and suffixes for teacher forcing technique\")\n",
        "    dummy_df = pd.DataFrame(output, columns=['input','output'])\n",
        "    return output, dummy_df          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NULb3334MwCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LanguageIndex():\n",
        "    def __init__(self, lang):\n",
        "        self.lang = lang\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "    def create_index(self):\n",
        "        for phrase in self.lang:\n",
        "            self.vocab.update(phrase.split(' '))\n",
        "        self.vocab = sorted(self.vocab)\n",
        "        self.word2idx[\"<pad>\"] = 0\n",
        "        self.idx2word[0] = \"<pad>\"\n",
        "        for i,word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = i + 1\n",
        "            self.idx2word[i+1] = word\n",
        "\n",
        "def max_length(t):\n",
        "    return max(len(i) for i in t)\n",
        "\n",
        "def load_dataset(corpus):\n",
        "    pairs, df = generate_dataset(corpus)\n",
        "    out_lang = LanguageIndex(sp for en, sp in pairs)\n",
        "    in_lang = LanguageIndex(en for en, sp in pairs)\n",
        "    input_data = [[in_lang.word2idx[s] for s in en.split(' ')] for en, sp in pairs]\n",
        "    output_data = [[out_lang.word2idx[s] for s in sp.split(' ')] for en, sp in pairs]\n",
        "    \n",
        "    max_length_in, max_length_out = max_length(input_data), max_length(output_data)\n",
        "    input_data = tf.keras.preprocessing.sequence.pad_sequences(input_data, maxlen=max_length_in, padding=\"post\")\n",
        "    output_data = tf.keras.preprocessing.sequence.pad_sequences(output_data, maxlen=max_length_out, padding=\"post\")\n",
        "    return input_data, output_data, in_lang, out_lang, max_length_in, max_length_out, df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUNfPsmMNB-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1de9cb9e-6562-494d-f3c2-ae6997fd3968"
      },
      "source": [
        "input_data, teacher_data, input_lang, target_lang, len_input, len_target, df = load_dataset(corpus)\n",
        "\n",
        "\n",
        "target_data = [[teacher_data[n][i+1] for i in range(len(teacher_data[n])-1)] for n in range(len(teacher_data))]\n",
        "target_data = tf.keras.preprocessing.sequence.pad_sequences(target_data, maxlen=len_target, padding=\"post\")\n",
        "target_data = target_data.reshape((target_data.shape[0], target_data.shape[1], 1))\n",
        "\n",
        "# Shuffle all of the data in unison. \n",
        "p = np.random.permutation(len(input_data))\n",
        "input_data = input_data[p]\n",
        "teacher_data = teacher_data[p]\n",
        "target_data = target_data[p]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset prepared with prefix and suffixes for teacher forcing technique\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0785qQOORKf1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "9cdd93af-c618-45e8-87e7-9ebf0a5e5369"
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "BUFFER_SIZE = len(input_data)\n",
        "BATCH_SIZE = 128\n",
        "embedding_dim = 300\n",
        "units = 128\n",
        "vocab_in_size = len(input_lang.word2idx)\n",
        "vocab_out_size = len(target_lang.word2idx)\n",
        "df.iloc[60:70]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>&lt;start&gt; equ &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ipment &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>&lt;start&gt; equi &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; pment &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>&lt;start&gt; equip &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ment &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>&lt;start&gt; equipm &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ent &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>&lt;start&gt; equipme &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; nt &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>&lt;start&gt; equipmen &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; t &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>&lt;start&gt; equipment &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt;  &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>&lt;start&gt; pr &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; essure &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>&lt;start&gt; pre &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; ssure &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>&lt;start&gt; pres &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; sure &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      input                output\n",
              "60  <start> equ <end>        <start> ipment <end>\n",
              "61  <start> equi <end>       <start> pment <end> \n",
              "62  <start> equip <end>      <start> ment <end>  \n",
              "63  <start> equipm <end>     <start> ent <end>   \n",
              "64  <start> equipme <end>    <start> nt <end>    \n",
              "65  <start> equipmen <end>   <start> t <end>     \n",
              "66  <start> equipment <end>  <start>  <end>      \n",
              "67  <start> pr <end>         <start> essure <end>\n",
              "68  <start> pre <end>        <start> ssure <end> \n",
              "69  <start> pres <end>       <start> sure <end>  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRdR_pFqVaIQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "6e66d315-358e-42b6-ef04-195dfcb382ee"
      },
      "source": [
        "# Create the Encoder layers first.\n",
        "encoder_inputs = Input(shape=(len_input,))\n",
        "encoder_emb = Embedding(input_dim=vocab_in_size, output_dim=embedding_dim)\n",
        "\n",
        "# Create the Bidirectional LSTM\n",
        "encoder_lstm = Bidirectional(LSTM(units=units, return_sequences=True, return_state=True))\n",
        "encoder_out, fstate_h, fstate_c, bstate_h, bstate_c = encoder_lstm(encoder_emb(encoder_inputs))\n",
        "state_h = Concatenate()([fstate_h,bstate_h])\n",
        "state_c = Concatenate()([bstate_h,bstate_c])\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "\n",
        "# Now create the Decoder layers.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_emb = Embedding(input_dim=vocab_out_size, output_dim=embedding_dim)\n",
        "decoder_lstm = LSTM(units=units*2, return_sequences=True, return_state=True)\n",
        "decoder_lstm_out, _, _ = decoder_lstm(decoder_emb(decoder_inputs), initial_state=encoder_states)\n",
        "# Two dense layers added to this model to improve inference capabilities.\n",
        "decoder_d1 = Dense(units, activation=\"relu\")\n",
        "decoder_d2 = Dense(vocab_out_size, activation=\"softmax\")\n",
        "decoder_out = decoder_d2(Dropout(rate=.2)(decoder_d1(Dropout(rate=.2)(decoder_lstm_out))))\n",
        "\n",
        "\n",
        "# Finally, create a training model which combines the encoder and the decoder.\n",
        "# Note that this model has three inputs:\n",
        "model = Model(inputs = [encoder_inputs, decoder_inputs], outputs= decoder_out)\n",
        "\n",
        "# We'll use sparse_categorical_crossentropy so we don't have to expand decoder_out into a massive one-hot array.\n",
        "# Adam is used because it's, well, the best.\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"sparse_categorical_crossentropy\", metrics=['sparse_categorical_accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 5, 300)       49200       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, 5, 256), (No 439296      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    39600       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256)          0           bidirectional[0][1]              \n",
            "                                                                 bidirectional[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256)          0           bidirectional[0][3]              \n",
            "                                                                 bidirectional[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 256),  570368      embedding_1[0][0]                \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, None, 256)    0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 128)    32896       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, None, 128)    0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 132)    17028       dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,148,388\n",
            "Trainable params: 1,148,388\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfxSjLCAY3qg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb64d543-f408-423e-e029-0379abad92b2"
      },
      "source": [
        "# Use 20% of our data for validation.\n",
        "epochs = 100\n",
        "history = model.fit([input_data, teacher_data], target_data,\n",
        "                 batch_size= BATCH_SIZE,\n",
        "                 epochs=epochs,\n",
        "                 validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1117 - sparse_categorical_accuracy: 0.9428 - val_loss: 1.3002 - val_sparse_categorical_accuracy: 0.8206\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1099 - sparse_categorical_accuracy: 0.9397 - val_loss: 1.2974 - val_sparse_categorical_accuracy: 0.8206\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1058 - sparse_categorical_accuracy: 0.9387 - val_loss: 1.2921 - val_sparse_categorical_accuracy: 0.8186\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1061 - sparse_categorical_accuracy: 0.9423 - val_loss: 1.2899 - val_sparse_categorical_accuracy: 0.8186\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1101 - sparse_categorical_accuracy: 0.9345 - val_loss: 1.2889 - val_sparse_categorical_accuracy: 0.8186\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1092 - sparse_categorical_accuracy: 0.9335 - val_loss: 1.2874 - val_sparse_categorical_accuracy: 0.8206\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1108 - sparse_categorical_accuracy: 0.9392 - val_loss: 1.2850 - val_sparse_categorical_accuracy: 0.8124\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1105 - sparse_categorical_accuracy: 0.9381 - val_loss: 1.2871 - val_sparse_categorical_accuracy: 0.8144\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1104 - sparse_categorical_accuracy: 0.9356 - val_loss: 1.2938 - val_sparse_categorical_accuracy: 0.8165\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1113 - sparse_categorical_accuracy: 0.9351 - val_loss: 1.3041 - val_sparse_categorical_accuracy: 0.8227\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1093 - sparse_categorical_accuracy: 0.9356 - val_loss: 1.3141 - val_sparse_categorical_accuracy: 0.8165\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1105 - sparse_categorical_accuracy: 0.9366 - val_loss: 1.3205 - val_sparse_categorical_accuracy: 0.8165\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1096 - sparse_categorical_accuracy: 0.9397 - val_loss: 1.3163 - val_sparse_categorical_accuracy: 0.8144\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1041 - sparse_categorical_accuracy: 0.9397 - val_loss: 1.3125 - val_sparse_categorical_accuracy: 0.8165\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1117 - sparse_categorical_accuracy: 0.9412 - val_loss: 1.3092 - val_sparse_categorical_accuracy: 0.8144\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1069 - sparse_categorical_accuracy: 0.9407 - val_loss: 1.3037 - val_sparse_categorical_accuracy: 0.8124\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1114 - sparse_categorical_accuracy: 0.9376 - val_loss: 1.3045 - val_sparse_categorical_accuracy: 0.8165\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1092 - sparse_categorical_accuracy: 0.9402 - val_loss: 1.3164 - val_sparse_categorical_accuracy: 0.8144\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1115 - sparse_categorical_accuracy: 0.9381 - val_loss: 1.3341 - val_sparse_categorical_accuracy: 0.8144\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1085 - sparse_categorical_accuracy: 0.9412 - val_loss: 1.3451 - val_sparse_categorical_accuracy: 0.8062\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1183 - sparse_categorical_accuracy: 0.9351 - val_loss: 1.3458 - val_sparse_categorical_accuracy: 0.8103\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1173 - sparse_categorical_accuracy: 0.9320 - val_loss: 1.3387 - val_sparse_categorical_accuracy: 0.8124\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1154 - sparse_categorical_accuracy: 0.9345 - val_loss: 1.3235 - val_sparse_categorical_accuracy: 0.8144\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1106 - sparse_categorical_accuracy: 0.9387 - val_loss: 1.3116 - val_sparse_categorical_accuracy: 0.8186\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1093 - sparse_categorical_accuracy: 0.9397 - val_loss: 1.3071 - val_sparse_categorical_accuracy: 0.8268\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1148 - sparse_categorical_accuracy: 0.9371 - val_loss: 1.3054 - val_sparse_categorical_accuracy: 0.8268\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1124 - sparse_categorical_accuracy: 0.9340 - val_loss: 1.3078 - val_sparse_categorical_accuracy: 0.8247\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1113 - sparse_categorical_accuracy: 0.9376 - val_loss: 1.3059 - val_sparse_categorical_accuracy: 0.8309\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1115 - sparse_categorical_accuracy: 0.9361 - val_loss: 1.3070 - val_sparse_categorical_accuracy: 0.8268\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1115 - sparse_categorical_accuracy: 0.9356 - val_loss: 1.3086 - val_sparse_categorical_accuracy: 0.8268\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1111 - sparse_categorical_accuracy: 0.9402 - val_loss: 1.3103 - val_sparse_categorical_accuracy: 0.8268\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1121 - sparse_categorical_accuracy: 0.9320 - val_loss: 1.3132 - val_sparse_categorical_accuracy: 0.8247\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1097 - sparse_categorical_accuracy: 0.9423 - val_loss: 1.3160 - val_sparse_categorical_accuracy: 0.8227\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1107 - sparse_categorical_accuracy: 0.9371 - val_loss: 1.3183 - val_sparse_categorical_accuracy: 0.8247\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1073 - sparse_categorical_accuracy: 0.9392 - val_loss: 1.3181 - val_sparse_categorical_accuracy: 0.8247\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1075 - sparse_categorical_accuracy: 0.9392 - val_loss: 1.3149 - val_sparse_categorical_accuracy: 0.8247\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1094 - sparse_categorical_accuracy: 0.9345 - val_loss: 1.3151 - val_sparse_categorical_accuracy: 0.8289\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1087 - sparse_categorical_accuracy: 0.9387 - val_loss: 1.3151 - val_sparse_categorical_accuracy: 0.8289\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1120 - sparse_categorical_accuracy: 0.9376 - val_loss: 1.3144 - val_sparse_categorical_accuracy: 0.8289\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1090 - sparse_categorical_accuracy: 0.9387 - val_loss: 1.3118 - val_sparse_categorical_accuracy: 0.8330\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1071 - sparse_categorical_accuracy: 0.9361 - val_loss: 1.3127 - val_sparse_categorical_accuracy: 0.8309\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1076 - sparse_categorical_accuracy: 0.9402 - val_loss: 1.3189 - val_sparse_categorical_accuracy: 0.8289\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1104 - sparse_categorical_accuracy: 0.9366 - val_loss: 1.3185 - val_sparse_categorical_accuracy: 0.8227\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1089 - sparse_categorical_accuracy: 0.9381 - val_loss: 1.3197 - val_sparse_categorical_accuracy: 0.8227\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1084 - sparse_categorical_accuracy: 0.9351 - val_loss: 1.3151 - val_sparse_categorical_accuracy: 0.8227\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1085 - sparse_categorical_accuracy: 0.9392 - val_loss: 1.3114 - val_sparse_categorical_accuracy: 0.8206\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1107 - sparse_categorical_accuracy: 0.9387 - val_loss: 1.3074 - val_sparse_categorical_accuracy: 0.8206\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1084 - sparse_categorical_accuracy: 0.9376 - val_loss: 1.3054 - val_sparse_categorical_accuracy: 0.8206\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1087 - sparse_categorical_accuracy: 0.9381 - val_loss: 1.3023 - val_sparse_categorical_accuracy: 0.8206\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1074 - sparse_categorical_accuracy: 0.9376 - val_loss: 1.3012 - val_sparse_categorical_accuracy: 0.8247\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1080 - sparse_categorical_accuracy: 0.9387 - val_loss: 1.3006 - val_sparse_categorical_accuracy: 0.8268\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1084 - sparse_categorical_accuracy: 0.9407 - val_loss: 1.3015 - val_sparse_categorical_accuracy: 0.8247\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1068 - sparse_categorical_accuracy: 0.9412 - val_loss: 1.3065 - val_sparse_categorical_accuracy: 0.8268\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1106 - sparse_categorical_accuracy: 0.9371 - val_loss: 1.3149 - val_sparse_categorical_accuracy: 0.8268\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1096 - sparse_categorical_accuracy: 0.9345 - val_loss: 1.3110 - val_sparse_categorical_accuracy: 0.8268\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1109 - sparse_categorical_accuracy: 0.9361 - val_loss: 1.3017 - val_sparse_categorical_accuracy: 0.8247\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1093 - sparse_categorical_accuracy: 0.9376 - val_loss: 1.2939 - val_sparse_categorical_accuracy: 0.8186\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1125 - sparse_categorical_accuracy: 0.9361 - val_loss: 1.2830 - val_sparse_categorical_accuracy: 0.8206\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1116 - sparse_categorical_accuracy: 0.9402 - val_loss: 1.2594 - val_sparse_categorical_accuracy: 0.8330\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1119 - sparse_categorical_accuracy: 0.9330 - val_loss: 1.2391 - val_sparse_categorical_accuracy: 0.8309\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1136 - sparse_categorical_accuracy: 0.9366 - val_loss: 1.2159 - val_sparse_categorical_accuracy: 0.8289\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1164 - sparse_categorical_accuracy: 0.9320 - val_loss: 1.2105 - val_sparse_categorical_accuracy: 0.8268\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1146 - sparse_categorical_accuracy: 0.9325 - val_loss: 1.2140 - val_sparse_categorical_accuracy: 0.8268\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1121 - sparse_categorical_accuracy: 0.9381 - val_loss: 1.2263 - val_sparse_categorical_accuracy: 0.8289\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1139 - sparse_categorical_accuracy: 0.9371 - val_loss: 1.2385 - val_sparse_categorical_accuracy: 0.8309\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1134 - sparse_categorical_accuracy: 0.9387 - val_loss: 1.2501 - val_sparse_categorical_accuracy: 0.8330\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1112 - sparse_categorical_accuracy: 0.9402 - val_loss: 1.2609 - val_sparse_categorical_accuracy: 0.8247\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1085 - sparse_categorical_accuracy: 0.9418 - val_loss: 1.2699 - val_sparse_categorical_accuracy: 0.8247\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1092 - sparse_categorical_accuracy: 0.9345 - val_loss: 1.2788 - val_sparse_categorical_accuracy: 0.8247\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1099 - sparse_categorical_accuracy: 0.9361 - val_loss: 1.2864 - val_sparse_categorical_accuracy: 0.8247\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1077 - sparse_categorical_accuracy: 0.9412 - val_loss: 1.2933 - val_sparse_categorical_accuracy: 0.8227\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1080 - sparse_categorical_accuracy: 0.9366 - val_loss: 1.3024 - val_sparse_categorical_accuracy: 0.8227\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1067 - sparse_categorical_accuracy: 0.9402 - val_loss: 1.3088 - val_sparse_categorical_accuracy: 0.8227\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1061 - sparse_categorical_accuracy: 0.9443 - val_loss: 1.3153 - val_sparse_categorical_accuracy: 0.8247\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1056 - sparse_categorical_accuracy: 0.9361 - val_loss: 1.3226 - val_sparse_categorical_accuracy: 0.8289\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1074 - sparse_categorical_accuracy: 0.9356 - val_loss: 1.3322 - val_sparse_categorical_accuracy: 0.8309\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1063 - sparse_categorical_accuracy: 0.9381 - val_loss: 1.3432 - val_sparse_categorical_accuracy: 0.8309\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1087 - sparse_categorical_accuracy: 0.9351 - val_loss: 1.3482 - val_sparse_categorical_accuracy: 0.8309\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1084 - sparse_categorical_accuracy: 0.9392 - val_loss: 1.3521 - val_sparse_categorical_accuracy: 0.8309\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1074 - sparse_categorical_accuracy: 0.9443 - val_loss: 1.3590 - val_sparse_categorical_accuracy: 0.8227\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1071 - sparse_categorical_accuracy: 0.9428 - val_loss: 1.3656 - val_sparse_categorical_accuracy: 0.8227\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1067 - sparse_categorical_accuracy: 0.9366 - val_loss: 1.3684 - val_sparse_categorical_accuracy: 0.8227\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1083 - sparse_categorical_accuracy: 0.9381 - val_loss: 1.3705 - val_sparse_categorical_accuracy: 0.8247\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1087 - sparse_categorical_accuracy: 0.9392 - val_loss: 1.3693 - val_sparse_categorical_accuracy: 0.8206\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1081 - sparse_categorical_accuracy: 0.9392 - val_loss: 1.3674 - val_sparse_categorical_accuracy: 0.8206\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1077 - sparse_categorical_accuracy: 0.9351 - val_loss: 1.3652 - val_sparse_categorical_accuracy: 0.8206\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1061 - sparse_categorical_accuracy: 0.9402 - val_loss: 1.3638 - val_sparse_categorical_accuracy: 0.8186\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1067 - sparse_categorical_accuracy: 0.9371 - val_loss: 1.3625 - val_sparse_categorical_accuracy: 0.8186\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1070 - sparse_categorical_accuracy: 0.9340 - val_loss: 1.3641 - val_sparse_categorical_accuracy: 0.8186\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1041 - sparse_categorical_accuracy: 0.9443 - val_loss: 1.3690 - val_sparse_categorical_accuracy: 0.8206\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1054 - sparse_categorical_accuracy: 0.9438 - val_loss: 1.3686 - val_sparse_categorical_accuracy: 0.8186\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1065 - sparse_categorical_accuracy: 0.9392 - val_loss: 1.3711 - val_sparse_categorical_accuracy: 0.8165\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1082 - sparse_categorical_accuracy: 0.9361 - val_loss: 1.3784 - val_sparse_categorical_accuracy: 0.8165\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1108 - sparse_categorical_accuracy: 0.9345 - val_loss: 1.3783 - val_sparse_categorical_accuracy: 0.8165\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1088 - sparse_categorical_accuracy: 0.9387 - val_loss: 1.3761 - val_sparse_categorical_accuracy: 0.8165\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1110 - sparse_categorical_accuracy: 0.9351 - val_loss: 1.3706 - val_sparse_categorical_accuracy: 0.8124\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1079 - sparse_categorical_accuracy: 0.9304 - val_loss: 1.3655 - val_sparse_categorical_accuracy: 0.8144\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1084 - sparse_categorical_accuracy: 0.9356 - val_loss: 1.3634 - val_sparse_categorical_accuracy: 0.8165\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1072 - sparse_categorical_accuracy: 0.9407 - val_loss: 1.3673 - val_sparse_categorical_accuracy: 0.8165\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1075 - sparse_categorical_accuracy: 0.9340 - val_loss: 1.3723 - val_sparse_categorical_accuracy: 0.8144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sCTcGDQaEl9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "99180941-bb2b-465a-e0d8-bf89c8f3b89b"
      },
      "source": [
        "# Plot the results of the training.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label=\"Training loss\")\n",
        "plt.plot(history.history['val_loss'], label=\"Validation loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1FZHiMDjIlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the encoder model from the tensors we previously declared.\n",
        "encoder_model = Model(encoder_inputs, [encoder_out, state_h, state_c])\n",
        "\n",
        "# Generate a new set of tensors for our new inference decoder. Note that we are using new tensors, \n",
        "# this does not preclude using the same underlying layers that we trained on. (e.g. weights/biases).\n",
        "\n",
        "inf_decoder_inputs = Input(shape=(None,), name=\"inf_decoder_inputs\")\n",
        "# We'll need to force feed the two state variables into the decoder each step.\n",
        "state_input_h = Input(shape=(units*2,), name=\"state_input_h\")\n",
        "state_input_c = Input(shape=(units*2,), name=\"state_input_c\")\n",
        "decoder_res, decoder_h, decoder_c = decoder_lstm(\n",
        "    decoder_emb(inf_decoder_inputs), \n",
        "    initial_state=[state_input_h, state_input_c])\n",
        "inf_decoder_out = decoder_d2(decoder_d1(decoder_res))\n",
        "inf_model = Model(inputs=[inf_decoder_inputs, state_input_h, state_input_c], \n",
        "                  outputs=[inf_decoder_out, decoder_h, decoder_c])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl1j-sPul7nv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts the given sentence (just a string) into a vector of word IDs\n",
        "# Output is 1-D: [timesteps/words]\n",
        "\n",
        "def sentence_to_vector(sentence, lang):\n",
        "\n",
        "    pre = sentence\n",
        "    vec = np.zeros(len_input)\n",
        "    sentence_list = [lang.word2idx[s] for s in pre.split(' ')]\n",
        "    for i,w in enumerate(sentence_list):\n",
        "        vec[i] = w\n",
        "    return vec\n",
        "\n",
        "# Given an input string, an encoder model (infenc_model) and a decoder model (infmodel),\n",
        "def translate(input_sentence, infenc_model, infmodel):\n",
        "    sv = sentence_to_vector(input_sentence, input_lang)\n",
        "    sv = sv.reshape(1,len(sv))\n",
        "    [emb_out, sh, sc] = infenc_model.predict(x=sv)\n",
        "    \n",
        "    i = 0\n",
        "    start_vec = target_lang.word2idx[\"<start>\"]\n",
        "    stop_vec = target_lang.word2idx[\"<end>\"]\n",
        "    \n",
        "    cur_vec = np.zeros((1,1))\n",
        "    cur_vec[0,0] = start_vec\n",
        "    cur_word = \"<start>\"\n",
        "    output_sentence = \"\"\n",
        "\n",
        "    while cur_word != \"<end>\" and i < (len_target-1):\n",
        "        i += 1\n",
        "        if cur_word != \"<start>\":\n",
        "            output_sentence = output_sentence + \" \" + cur_word\n",
        "        x_in = [cur_vec, sh, sc]\n",
        "        [nvec, sh, sc] = infmodel.predict(x=x_in)\n",
        "        cur_vec[0,0] = np.argmax(nvec[0,0])\n",
        "        cur_word = target_lang.idx2word[np.argmax(nvec[0,0])]\n",
        "    return output_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi5K270pl9HP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "07680a60-0494-4eec-eaa6-6f36d749f7e9"
      },
      "source": [
        "#Note that only words that we've trained the model on will be available, otherwise you'll get an error.\n",
        "\n",
        "\n",
        "test = [\n",
        "    'desc', \n",
        "    'fl',\n",
        "    'ope',\n",
        "    'value',\n",
        "    'flow',\n",
        "    'auto',\n",
        "    'gas',\n",
        "    'log'\n",
        "]\n",
        "  \n",
        "\n",
        "import pandas as pd\n",
        "output = []  \n",
        "for t in test:  \n",
        "  output.append({\"Input seq\":t.lower(), \"Pred. Seq\":translate(t.lower(), encoder_model, inf_model)})\n",
        "\n",
        "results_df = pd.DataFrame.from_dict(output) \n",
        "results_df.head(len(test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input seq</th>\n",
              "      <th>Pred. Seq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>desc</td>\n",
              "      <td>parameter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fl</td>\n",
              "      <td>n set whether</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ope</td>\n",
              "      <td>ration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>value</td>\n",
              "      <td>page</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>flow</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>auto</td>\n",
              "      <td>cept command</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>gas</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>log</td>\n",
              "      <td>parameter</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Input seq       Pred. Seq\n",
              "0  desc        parameter   \n",
              "1  fl         n set whether\n",
              "2  ope        ration       \n",
              "3  value       page        \n",
              "4  flow                    \n",
              "5  auto       cept command \n",
              "6  gas                     \n",
              "7  log         parameter   "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vK5lhBpmHmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is to save the model for the web app to use for generation\n",
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "\n",
        "# serialize model to JSON\n",
        "#  the keras model which is trained is defined as 'model' in this example\n",
        "model_json = inf_model.to_json()\n",
        "\n",
        "\n",
        "with open(\"./sample_data/model_num.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# serialize weights to HDF5\n",
        "inf_model.save_weights(\"./sample_data/model_num.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af1uMK4y4n2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}